{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate q-learning\n",
    "\n",
    "In this notebook you will teach a lasagne neural network to do Q-learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Frameworks__ - we'll accept this homework in any deep learning framework. For example, it translates to TensorFlow almost line-to-line. However, we recommend you to stick to theano/lasagne unless you're certain about your skills in the framework of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting virtual X frame buffer: Xvfb../xvfb: line 8: start-stop-daemon: command not found\n",
      ".\n",
      "env: DISPLAY=:1\n"
     ]
    }
   ],
   "source": [
    "#XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-05 10:13:12,790] Making new env: CartPole-v0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x113c34650>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFkCAYAAAB1rtL+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112a87590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate (deep) Q-learning: building the network\n",
    "\n",
    "In this section we will build and train naive Q-learning with theano/lasagne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is initializing input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "# create input variables. We'll support multiple states at once\n",
    "current_states = T.matrix(\"states[batch,units]\")\n",
    "actions = T.ivector(\"action_ids[batch]\")\n",
    "rewards = T.vector(\"rewards[batch]\")\n",
    "next_states = T.matrix(\"next states[batch,units]\")\n",
    "is_end = T.ivector(\"vector[batch] where 1 means that session just ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "from lasagne.nonlinearities import *\n",
    "\n",
    "# neural network\n",
    "l_states = InputLayer((None,)+state_dim)\n",
    "l_nn = DenseLayer(l_states, 128, nonlinearity=elu)\n",
    "l_nn = DenseLayer(l_nn, 128, nonlinearity=elu)\n",
    "l_qvalues = DenseLayer(l_nn, n_actions, nonlinearity=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting Q-values for `current_states`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get q-values for ALL actions in current_states\n",
    "predicted_qvalues = get_output(l_qvalues,{l_states:current_states})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compiling agent's \"GetQValues\" function\n",
    "#get_qvalues = <compile a function that takes current_states and returns predicted_qvalues>\n",
    "get_qvalues = theano.function([current_states], predicted_qvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select q-values for chosen actions\n",
    "predicted_qvalues_for_actions = predicted_qvalues[T.arange(actions.shape[0]),actions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function and `update`\n",
    "Here we write a function similar to `agent.update`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predict q-values for next states\n",
    "predicted_next_qvalues = get_output(l_qvalues, {l_states: next_states})\n",
    "\n",
    "#Computing target q-values under \n",
    "gamma = 0.99\n",
    "\n",
    "#target_qvalues_for_actions = <target Q-values using rewards and predicted_next_qvalues>\n",
    "target_qvalues_for_actions = rewards + gamma * predicted_next_qvalues.max(-1)\n",
    "\n",
    "#zero-out q-values at the end\n",
    "target_qvalues_for_actions = (1-is_end)*target_qvalues_for_actions\n",
    "\n",
    "#don't compute gradient over target q-values (consider constant)\n",
    "target_qvalues_for_actions = theano.gradient.disconnected_grad(target_qvalues_for_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mean squared error loss function between target_qvalues_for_actions and predicted_qvalues_for_actions\n",
    "loss = lasagne.objectives.squared_error(target_qvalues_for_actions, predicted_qvalues_for_actions).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all network weights\n",
    "all_weights = get_all_params(l_qvalues, trainable=True)\n",
    "\n",
    "# network updates. Note the small learning rate (for stability)\n",
    "updates = lasagne.updates.sgd(loss, all_weights, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Training function that resembles agent.update(state,action,reward,next_state) \n",
    "#with 1 more argument meaning is_end\n",
    "train_step = theano.function([current_states,actions,rewards,next_states,is_end],\n",
    "                             updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epsilon = 0.25 #initial epsilon\n",
    "\n",
    "def generate_session(t_max=1000):\n",
    "    \"\"\"play env with approximate q-learning agent and train it at the same time\"\"\"\n",
    "    \n",
    "    total_reward = 0\n",
    "    s = env.reset()\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        \n",
    "        #get action q-values from the network\n",
    "        q_values = get_qvalues([s])[0] \n",
    "        \n",
    "        # sample action with epsilon-greedy strategy\n",
    "        if (np.random.rand() < epsilon):\n",
    "            a = np.random.randint(len(q_values)) # random action\n",
    "        else:\n",
    "            a = np.argmax(q_values) # best action\n",
    "        \n",
    "        new_s,r,done,info = env.step(a)\n",
    "        \n",
    "        #train agent one step. Note that we use one-element arrays instead of scalars \n",
    "        #because that's what function accepts.\n",
    "        train_step([s],[a],[r],[new_s],[done])\n",
    "        \n",
    "        total_reward+=r\n",
    "        \n",
    "        s = new_s\n",
    "        if done: break\n",
    "            \n",
    "    return total_reward\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward:11.420\tepsilon:0.23750\n",
      "mean reward:10.560\tepsilon:0.22562\n",
      "mean reward:10.780\tepsilon:0.21434\n",
      "mean reward:10.600\tepsilon:0.20363\n",
      "mean reward:10.200\tepsilon:0.19345\n",
      "mean reward:10.420\tepsilon:0.18377\n",
      "mean reward:10.510\tepsilon:0.17458\n",
      "mean reward:10.720\tepsilon:0.16586\n",
      "mean reward:13.460\tepsilon:0.15756\n",
      "mean reward:13.900\tepsilon:0.14968\n",
      "mean reward:17.290\tepsilon:0.14220\n",
      "mean reward:17.910\tepsilon:0.13509\n",
      "mean reward:21.180\tepsilon:0.12834\n",
      "mean reward:28.370\tepsilon:0.12192\n",
      "mean reward:29.690\tepsilon:0.11582\n",
      "mean reward:25.420\tepsilon:0.11003\n",
      "mean reward:26.340\tepsilon:0.10453\n",
      "mean reward:32.530\tepsilon:0.09930\n",
      "mean reward:35.540\tepsilon:0.09434\n",
      "mean reward:42.080\tepsilon:0.08962\n",
      "mean reward:47.030\tepsilon:0.08514\n",
      "mean reward:53.400\tepsilon:0.08088\n",
      "mean reward:74.570\tepsilon:0.07684\n",
      "mean reward:141.420\tepsilon:0.07300\n",
      "mean reward:169.240\tepsilon:0.06935\n",
      "mean reward:143.780\tepsilon:0.06588\n",
      "mean reward:118.210\tepsilon:0.06259\n",
      "mean reward:245.060\tepsilon:0.05946\n",
      "mean reward:84.970\tepsilon:0.05648\n",
      "mean reward:56.130\tepsilon:0.05366\n",
      "mean reward:58.070\tepsilon:0.05098\n",
      "mean reward:93.740\tepsilon:0.04843\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    \n",
    "    rewards = [generate_session() for _ in range(100)] #generate new sessions\n",
    "    \n",
    "    epsilon*=0.95\n",
    "    \n",
    "    print (\"mean reward:%.3f\\tepsilon:%.5f\"%(np.mean(rewards),epsilon))\n",
    "    \n",
    "    plt.cl\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "\n",
    "    if np.mean(rewards) > 300:\n",
    "        print (\"You Win!\")\n",
    "        break\n",
    "        \n",
    "    assert epsilon!=0, \"Please explore environment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon=0 #Don't forget to reset epsilon back to initial value if you want to go on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#record sessions\n",
    "import gym.wrappers\n",
    "env = gym.wrappers.Monitor(env,directory=\"videos\",force=True)\n",
    "sessions = [generate_session() for _ in range(100)]\n",
    "env.close()\n",
    "#unwrap \n",
    "env = env.env.env\n",
    "#upload to gym\n",
    "#gym.upload(\"./videos/\",api_key=\"<your_api_key>\") #you'll need me later\n",
    "\n",
    "#Warning! If you keep seeing error that reads something like\"DoubleWrapError\",\n",
    "#run env=gym.make(\"CartPole-v0\");env.reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./videos/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./videos/\"+video_names[-1])) #this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Homework\n",
    "\n",
    "Two paths lie ahead of you, and which one to take is a rightfull choice of yours.\n",
    "\n",
    "* __[recommended]__ Go deeper. Return to seminar1 and get 99% accuracy on MNIST\n",
    "* __[alternative]__ Try approximate expected-value SARSA and other algorithms and compare it with q-learning \n",
    "  * +3 points for EV-SARSA and comparison to Q-learning\n",
    "  * +2 per additional algorithm\n",
    "* __[alternative hard]__ Pick ```<your favourite env>``` and solve it, using NN.\n",
    " * LunarLander, MountainCar or Breakout (from week1 bonus)\n",
    " * LunarLander should get at least +100\n",
    " * MountainCar should get at least -200\n",
    " * You will need to somehow stabilize learning\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 1 if False else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
